---
title: "TSRchitect vignette"
author: "R. Taylor Raborn"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TSRchitect vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# TSRchitect

## R. Taylor Raborn and Volker P. Brendel
## Department of Biology, Indiana University

### January 17, 2017

TSRchitect is an R package for analyzing diverse types of high-throughput transcription start site (TSS) profiling datasets. TSRchitect can handle TSS profiling experiments that contain either single-end orb paired-end sequence. In recent years, large-scale TSS profiling data has characterized the landscape of transcription initiation at high resolution, identifying promoter architecture in a number of eukaryotic model systems, including human, mouse, fruit fly and worm.

Examples of TSS profiling data types that TSRchitect is capable of handling are as follows:

- CAGE (Cap Analysis of Gene Expression) [Single-end]
- PEAT (Paired-end Analysis of Transcription) [Paired-end]
- RAMPAGE (RNA Annotation and Mapping of Promoters for Analysis of Gene Expression) [Paired-end]
- TSS-seq [Single-end]

TSRchitect provides the capability to efficiently identify putative promoters---which we call transcription start regions (TSRs)---from TSS profiling experiments. TSRchitect possesses the flexibility to accomodate datasets, including biological replicates and multiple tissues/conditions, that were generated in a variety of model organisms and genome assemblies, requiring only aligned TSS profiling information (in BAM format) as the initial input. To aid the downstream analysis of identified promoters, TSRchitect calcualtes a variety of TSR properties that have been shown to be associated with promoter architecture, including TSR activity, width and the Shape Index (SI). Finally, TSRchitect's output is compatible with popular differential expression analyses such as edgeR, assisting in downstream analysis to identify TSRs that are differentially active in one sample versus another. In addition to this vignette, the TSRchitect Reference Manual is available as part of the package's online documentation.

## Getting started

To load TSRchitect, please enter the following into an R console:

```{r eval=FALSE}
library(TSRchitect)
```

Now that this is complete, we proceed with the first of the three examples contained in this vignette.

## Example 1: Identifying promoters from RAMPAGE data derived from two human cell lines.

RAMPAGE is a TSS profiling method that identifies promoters at large-scale using a cap-based library construction method that is adapted for paired-end sequencing. Developed recently by Batut and Gingeras (2013), it has become a popular method for promoter identification and is currently part of the data compredium in the latest edition of the ENCODE project.

In this example we will process RAMPAGE data derived from two immortalized human cell lines with TSRchitect. The experiments selected for this vignette are part of the ENCODE project and is publically available online at the [ENCODE Experiment matrix](https://www.encodeproject.org/matrix/?type=Experiment). The two samples come from HT1080 cells, which is a well-characterized fibrosarcoma cell line, and NCI-H460 cells, which are derived from a large cell lung carcinoma in a male patient. 

To begin, we must first download the RAMPAGE datasets (which were aligned to GRCh38 and are in BAM format) to our local system. To accomplish this we will utilize the "ENCODExplorer" package, which is part of the Bioconductor suite. More information on ENCODExplorer package can be found at the following link: https://www.bioconductor.org/packages/release/bioc/html/ENCODExplorer.html.

Now we can proceed with downloading the data:

```{r eval=FALSE}
library(ENCODExplorer)
data(encode_df, package = "ENCODExplorer")
datasets <- fuzzySearch(searchTerm = c("ENCFF474YPI", "ENCFF242UWH", "ENCFF214GWH", "ENCFF265SGZ"), database = encode_df, filterVector = c("file_accession"), multipleTerm = TRUE)
downloadEncode(datasets, df=encode_df, format="bam") #downloading the files
```

Once the above steps are complete, we will move the files into a new folder called `hsRAMPAGE/` inside the demo/ folder.

```{bash eval=FALSE}
cd ../demo #assumes the user is in /vignettes
mkdir demo/hsRAMPAGE
cd hsRAMPAGE
ln -s ../ENCFF214GWH.bam H460-rep1.bam
ln -s ../ENCFF265SGZ.bam H460-rep2.bam
ln -s ../ENCFF474YPI.bam HT1080-rep1.bam
ln -s ../ENCFF242UWH.bam HT1080-rep2.bam
```

We'll also need to download a human gene annotation, which will be important a little later.

Please download and uncompress the annoation file and place it in the `demo/` folder.

The file is found here:
ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gff3.gz

Now that we have our input and annotation files prepared, we can load TSRchitect into our workspace, along with another library required for parallelization:

```{r eval=FALSE}
#loading TSRchitect
library(TSRchitect)
```

```{r eval=FALSE}
#loading the doParallel package, which is requried for parallel processing
library(doParallel) 
```

To implement parallelization, we'll need to set up a cluster of 6 nodes first. (Please adjust the number of clusters as you desire and your compute permits):

```{r eval=FALSE}
mycl <- makeCluster(5,type="FORK",outfile="")
registerDoParallel(mycl)
```

Next we'll create the dedicated S4 object---called the tssObject---that TSRchitect's functions will be performed on.

```{r eval=FALSE}
initializeExp(expTitle ="Human RAMPAGE", experimentName="Hs_RAMPAGE", expDir="demo/bam_files/", isPairedEnd=TRUE) 
```

This will create an object called `Hs_RAMPAGE`, in your workspace. We specified the directory "vignette_files" as the location of the bam files to be imported, and have given it the rather general title "Human RAMPAGE". Before we continue, let's take a look look at the object in our workspace using `ls()` to make sure it appears.

Now we need to provide the sample names and specify which samples are biological replicates. In this case we are working with 4 total datasets and 2 samples in duplicate. Please note that, because the alignments on our @bamData slot are organized in ascending alphabetical order (as are the file names on the @fileNames slot), we provide must provide our identifiers in `sample.names` and `replicateIDs` to directly correspond to this. To check this on the tssObject S4 object you have created, simply check the list of bam files as follows:

```{r eval=FALSE}
#obtaining the list of bam files loaded to the tssObject S4 object
Hs_RAMPAGE@fileNames
```

```{r eval=FALSE}
setSampleID(Hs_RAMPAGE, sample.names=c("H460-rep1", "H460-rep2","HT1080-rep1","HT1080-rep2"), replicate.IDs=c(1,1,2,2))
```

Now that we have completed the above commands, we can proceed with importing the bam files using the function `importBam`. This will attach GenomicAlignments objects (representing the four bam files in this example) to your tssObject. 

```{r eval=FALSE}
importBam(Hs_RAMPAGE)
```
You will receive a message on your console when all four files have been imported:

Now that the alignment files have been imported and attached to our tssObject S4 object, we continue by computing the TSSs from the bam files.

```{r eval=FALSE}
bamToTSS(experimentName=Hs_RAMPAGE)
```

Next we will calculate the abundance of each tag in our TSS datasets.

```{r eval=FALSE}
processTSS(experimentName=Hs_RAMPAGE, parallel=TRUE, tssSet="all", writeTable=TRUE)
```

Since we specified 'writeTable=TRUE', files (entitled "TSSset-1.txt" to "TSSset-4.txt") containing TSS abundance will be written into your working directory. 

Now that we have calculated the abundance for each TSS in the previous step we can calculate TSRs (promoters) on each of the 4 separate datasets. We have selected a tagCount threshold of 25 tags in order for a TSS to be considered. As with the previous step, we selected 'writeTable=TRUE' and therefore you will find the file ("TSRset-1" to "TSRset-4") written to your working directory.

```{r eval=FALSE}
determineTSR(experimentName = Hs_RAMPAGE, parallel = TRUE, tsrSetType = "replicates", tssSet="all", tagCountThreshold=25, clustDist=20, writeTable=TRUE)
```

To calculate TSRs from each sample (as opposed to each replicate) we need to combine our replicate data. This will be done using the identifiers we specified on our tssObject S4 object using the function initializeExp().

```{r eval=FALSE}
mergeSampleData(experimentName=Hs_RAMPAGE)
```

Having combined the TSS abundance of replicate data into samples, we next proceed with identifying TSRs for the two samples individually. We specify this with 'tsrSetType="merge"'.

```{r eval=FALSE}
determineTSR(experimentName = Hs_RAMPAGE, parallel = TRUE, tsrSetType = "merged", tssSet="all", tagCountThreshold=40, clustDist=20, writeTable=TRUE)
stopCluster(mycl) #ending the parallel session we set up earlier in the vignette.
```

Now we will calculate the number of tags from each experiment within the combined set of TSRs.

```{r eval=FALSE}
addTagCountsToTSR(experimentName= Hs_RAMPAGE, tsrSetType= "merged", tsrSet=3, tagCountThreshold= 40, writeTable= TRUE)
```

### Associating identified TSRs with gene annotations

Now that identifying TSRs are complete an obvious and biologically useful step is to determine which TSRs are adjacent to annotated genes, and to retrieve the appropriate gene IDs. Before doing this, it is imperative to select an annotation file that was generated for the assembly the reads were aligned to. Please make sure you have already downloaded the annotation file linked to at the beginning of this vignette.

```{r eval=FALSE}
importAnnotation(experimentName = Hs_RAMPAGE, fileType = "gff3", annotFile = "vignettes/gencode.v19.annotation.gff3")
```
Now we will associate the gene annotation to the TSRs within our two merged samples. We selected the feature 'transcript' from the Gencode annotation. 

```{r eval=FALSE}
addAnnotationToTSR(experimentName = Hs_RAMPAGE, tsrSetType="merged", tsrSet=1, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE)

addAnnotationToTSR(experimentName = Hs_RAMPAGE, tsrSetType="merged", tsrSet=2, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE)
```

Finally, we will repeat the two commands above, only associating the gene annotation to the "combined" set of TSRs, which is found in the 3rd position on the @tsrDataMerged slot.

```{r eval=FALSE}
addAnnotationToTSR(experimentName = Hs_RAMPAGE, tsrSetType="merged", tsrSet=3, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE)
```

Let's briefly look at our sets of identified TSRs.

```{r eval=FALSE}
Hs_RAMPAGE@tsrDataMerged[[1]] -> H460.tsrs
dim(H460.tsrs)
```

```{r eval=FALSE}
Hs_RAMPAGE@tsrDataMerged[[2]] -> HT1080.tsrs
dim(HT1080.tsrs)
```

```{r eval=FALSE}
Hs_RAMPAGE@tsrDataMerged[[3]] -> combined.tsrs
dim(combined.tsrs)
```

[1] 22750    12

We see that there are 22750 TSRs identified in the combined set, and 15904 and 18040 TSRs in the H460 and HT1080 samples, respectively. We also notice that there are 5 additional columns in the combined set. This is due to us previouly adding tag counts to the combined set of tSRs using addTagCountsToTSR, something we did not do in this vignette for the two samples.

You now have a complete set of TSS and TSR data attached to your tssObject S4 object, in addition the tables that were already written to your working directory.

These data can be accessed from the tssObject simply. For example, if we want to copy the TSR annotations from the HT1080 cells onto our R workspace, we could type the following command:

```{r eval=FALSE}
# retrieving TSR data from the tssObject S4 object
Hs_RAMPAGE@tsrDataMerged[[1]] -> H460.tsrs
head(H460.tsrs) #printing the first few rows of the table to our console.
```

This concludes Example 1. Should we wish to save our tssObject and return to our work later, we simply type the following, which will write an R binary to your working directory.

```{r eval=FALSE}
save(Hs_RAMPAGE, file="Hs_RAMPAGE.RData")
```

Important note: before you continue with another example, please move the output files generated in your working directory to a separate, dedicated folder. Otherwise some or all of the files you generate in subsequent examples will be overwritten.

## Example 2: Identifying promoters in the model plant A. thaliana using a PEAT dataset.

For our second example will process TSS profiling data from Arabidopsis root tissue. This data comes from the Megraw Lab of Oregon State University and was reported in Morton et al., 2014. [Link to paper:](http://www.plantcell.org/content/26/7/2746)

As with the previous example, we first must download the raw data. In this case we have only a single alignment file to retrieve, which is found here: http://megraw.cgrb.oregonstate.edu/jbrowse_public/arabidopsis_public/webdata/peat/peat.sorted.bam .

The annotation dataset is available from the TAIR10 database: ftp://ftp.arabidopsis.org/home/tair/Genes/TAIR10_genome_release/TAIR10_gff3/TAIR10_GFF3_genes.gff . Please place this file in the `demo/` folder.

Once download of the file `peat.sorted.bam` is complete, please move it to a directory within `demo/` entitled "PEAT_bam".
Since there is only a single experiment, setting the sample IDs is simple:

```{r eval=FALSE}
initializeExp(expTitle="Arabidopsis PEAT dataset", experimentName="At_PEAT", expDir="demo/PEAT_bam", isPairedEnd=TRUE)
setSampleID(experimentName=At_PEAT, sample.names=c("experiment1"), replicate.IDs=c(1))
```

Now we import the alignment file to our tssObject S4 object and convert the data to TSS coordinates:

```{r eval=FALSE}
importBam(At_PEAT)
bamToTSS(At_PEAT)
```

As in the previous example, now we can calculate the tag abundance at each location using `processTSS` and the identify TSRs within the sample using `determineTSR`. Note that we do not need to use `mergeDampleData` because there is only a single sample.

```{r eval=FALSE}
processTSS(experimentName=At_PEAT, parallel=FALSE, tssSet="all", writeTable=TRUE)
determineTSR(experimentName=At_PEAT, parallel=FALSE, tsrSetType="replicates", tssSet="all", tagCountThreshold=25, clustDist=20, writeTable=TRUE)
stopCluster(mycl) #ending the parallel session we set up earlier in this example.
```

### Associating identified TSRs with gene annotations

We continue by associating our newly-identified TSRs with genes from the TAIR10 annotation. Note that we use different parameters for upstreamDist and downstreamDist than we did in Example 1. This is due to the high degree of compactness in the A. thaliana genome.

```{r eval=FALSE}
importAnnotation(experimentName=At_PEAT, fileType="gff3", annotFile="demo/TAIR10_GFF3_genes.gff")
addAnnotationToTSR(experimentName=At_PEAT, tsrSetType="replicates", tsrSet=1, upstreamDist=1000, downstreamDist=200, feature="gene", featureColumnID="ID", writeTable=TRUE)
```

Now we have a complete set of TSRs on our tssObject object. Let's take a look at them:

```{r eval=FALSE}
At.tsrs <- AtPEAT@tsrDataMerged[[1]]
dim(At.tsrs)
head(At.tsrs)
```

We can optionally save the tssObject as we have previously.

```{r eval=FALSE}
save(At_PEAT, file="At_PEAT_vignette.RData")
```

## Example 3: Analysis of CAGE datasets from the FANTOM project

As we stated in the introduction of this vignette, TSRchitect is capable of handling diverse forms of TSS profiling data. In the first two examples, we analyze two distinct paired-end datasets: RAMPAGE and PEAT, respectively. In this example we will process data from CAGE, which is most widely-used TSS profiling method to date.  We will analyze CAGE data generated in two well-characterized immortalized cell lines, MCF-7 and A549. MCF-7 cells are derived from a breast cancer tumor, and A549 originates from an adenocarinoma isolated from lung tissue. Both datasets are part of the ENCODE project, and therefore we can make use of the ENCODExplorer package that we originally introduced in Example 1 (see https://www.bioconductor.org/packages/release/bioc/html/ENCODExplorer.html information on installation).

```{r eval=FALSE}
library(ENCODExplorer)
data(encode_df, package = "ENCODExplorer")
cage_data <- fuzzySearch(searchTerm = c("ENCFF552BXH","ENCFF288VTZ","ENCFF265RSX","ENCFF944PCJ"), database = encode_df, filterVector = c("file_accession"), multipleTerm = TRUE)
downloadEncode(cage_data, df=encode_df, format="bam") #downloading the files
```

Now that the files have been downloaded, we will create symbolic links with the appropriate sample names. Please run the following commands from a linux command line:

```{bash eval=FALSE}
cd ../demo #assumes the user is in /vignettes
mkdir hsCAGE
cd hsCAGE
ln -s ../ENCFF265RSX.bam A549-rep1.bam
ln -s ../ENCFF944PCJ.bam A549-rep2.bam
ln -s ../ENCFF552BXH.bam MCF7-rep1.bam
ln -s ../ENCFF288VTZ.bam MCF7-rep2.bam
```

As in Example 1, we also need to download a human gene annotation.  Please download, uncompress the annoation file and place it in the `demo/` folder. [Note: you may ignore this is you have already downloaded the file from Example 1]

The annotation file is found at the following location:
ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_19/gencode.v19.annotation.gff3.gz

Now we can set up the tssObject S4 object. Note that we must specify `isPairedEnd=FALSE` because this is single-end CAGE data.

```{r eval=FALSE}
# initializing the tssObject
initializeExp(expTitle ="Human CAGE experiment", experimentName="CAGEhuman", expDir="demo/hsCAGE", isPairedEnd=FALSE)
```

Now we set the sample IDs. As before, it is vital to provide `sample.names` and `replicate.IDs` in the order of the files on the @fileNames slot to they exactly correspond to the bam data that we imported.

```{r eval=FALSE}
# setting the sample IDs and names for the datasets within the CAGE library
setSampleID(experimentName=CAGEhuman, sample.names=c("A549-rep1","A549-rep2", "MCF7-rep1","MCF7-rep2"), replicate.IDs=c(1,1,2,2)) 
```

As in the prior two examples, we then import the BAM files and obtain TSSs from this data.

```{r eval=FALSE}
# loading the BAM files from CAGE experiment
importBam(experimentName=CAGEhuman)
```

```{r eval=FALSE}
# converting BAM data into TSS information and attaching it to the tssObject:
bamToTSS(experimentName=CAGEhuman)
```

As we did in our first example, we need to set up a parallel instance as follows:

```{r eval=FALSE}
# setting up a parallel instance
library(doParallel)
mycl <- makeCluster(5,type="FORK",outfile="")
registerDoParallel(mycl)
```

Next we must calculate the CAGE tag abundance at each TSS position, followed by identification of TSRs within our 4 replicate datasets.

```{r eval=FALSE}
# constructing the tag count per TSS data matrix:
processTSS(experimentName=CAGEhuman, parallel=TRUE, tssSet="all", writeTable=TRUE)
```
```{r eval=FALSE}
# finding TSRs for the replicate datasets
determineTSR(experimentName=CAGEhuman, parallel=TRUE, tsrSetType="replicates", tssSet="all", tagCountThreshold=25, clustDist=20, writeTable=TRUE)
```

Now we merge data from replicates into their two corresponding samples.

```{r eval=FALSE}
#merging TSS data from the replicates
mergeSampleData(experimentName=CAGEhuman) 
```

Once this is complete, we can complete TSR identification on the merged samples.

```{r eval=FALSE}
# finding TSRs for the merged samples
determineTSR(experimentName=CAGEhuman, parallel=TRUE, tsrSetType="merged", tssSet="all", tagCountThreshold=40, clustDist=20, writeTable=TRUE) 
```

```{r eval=FALSE}
addTagCountsToTSR(experimentName= CAGEhuman, tsrSetType= "merged", tsrSet=3, tagCountThreshold= 40, writeTable= TRUE)
```
Now we need to import the annotation file and attach it to our tssObject S4 object.

```{r eval=FALSE}
importAnnotation(experimentName = CAGEhuman, fileType = "gff3", annotFile = "demo/gencode.v19.annotation.gff3")
```

Now we will associate the gene annotation to the TSRs within our two merged samples. As we did in Example 1, we select the feature 'transcript' from the Gencode annotation.

Associating the annotation features with the TSRs from i) MCF7 cells and ii) A549 cells:

```{r eval=FALSE}
addAnnotationToTSR(experimentName = CAGEhuman, tsrSetType="merged", tsrSet=1, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE) #A549 cells
addAnnotationToTSR(experimentName = CAGEhuman, tsrSetType="merged", tsrSet=2, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE) #MCF7 cells
```

Associating our selected annotation features with the TSRs on the 'combined' slot.

```{r eval=FALSE}
addAnnotationToTSR(experimentName = CAGEhuman, tsrSetType="merged", tsrSet=3, upstreamDist=1000, downstreamDist=200, feature="transcript", featureColumnID="ID", writeTable=TRUE)
```

Let's take a quick glance at our combined set of identified TSRs:


```{r eval=FALSE}
CAGEhuman@tsrDataMerged[[1]] -> A549.tsrs
dim(A549.tsrs)
```

```{r eval=FALSE}
CAGEhuman@tsrDataMerged[[2]] -> MCF7.tsrs
dim(MCF7.tsrs)
```

```{r eval=FALSE}
CAGEhuman@tsrDataMerged[[3]] -> CAGEhuman.tsrs
dim(CAGEhuman.tsrs)
```

We can now optionally save the tssObject for future use.

```{r eval=FALSE}
save(CAGEhuman, file="CAGEhuman-vignette.RData")
```